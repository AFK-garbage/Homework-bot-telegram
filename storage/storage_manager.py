import os
import sqlite3
import asyncio
import uuid
import json
import shutil
import zipfile
from abc import ABC, abstractmethod
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
from .yandex_storage import YandexCloudStorage
import logging


logger = logging.getLogger(__name__)

# ==================== –ê–ë–°–¢–†–ê–ö–¢–ù–´–ï –ö–õ–ê–°–°–´ ====================

class StorageProvider(ABC):
    """–ê–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ —Ö—Ä–∞–Ω–µ–Ω–∏—è"""
    
    @abstractmethod
    async def save(self, file_content: bytes, filename: str, metadata: dict = None) -> Dict[str, Any]:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ñ–∞–π–ª, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏"""
        pass
    
    @abstractmethod
    async def get(self, file_id: str) -> bytes:
        """–ü–æ–ª—É—á–∞–µ—Ç —Ñ–∞–π–ª –ø–æ ID"""
        pass
    
    @abstractmethod
    async def delete(self, file_id: str) -> bool:
        """–£–¥–∞–ª—è–µ—Ç —Ñ–∞–π–ª"""
        pass
    
    @abstractmethod
    def get_usage_stats(self) -> Dict[str, Any]:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
        pass

# ==================== –õ–û–ö–ê–õ–¨–ù–û–ï –•–†–ê–ù–ò–õ–ò–©–ï ====================

class LocalStorage(StorageProvider):
    """–õ–æ–∫–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–∞ –¥–∏—Å–∫–µ"""
    
    def __init__(self, base_path: str = "./storage"):
        self.base_path = os.path.abspath(base_path)
        self._ensure_directory()
        logger.info(f"–õ–æ–∫–∞–ª—å–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ: {self.base_path}")
    
    def _ensure_directory(self):
        """–°–æ–∑–¥–∞–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç"""
        os.makedirs(self.base_path, exist_ok=True)
        os.makedirs(os.path.join(self.base_path, "files"), exist_ok=True)
        os.makedirs(os.path.join(self.base_path, "metadata"), exist_ok=True)
    
    async def save(self, file_content: bytes, filename: str, metadata: dict = None) -> Dict[str, Any]:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ñ–∞–π–ª –ª–æ–∫–∞–ª—å–Ω–æ"""
        try:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –¥–ª—è —Ñ–∞–π–ª–∞
            ext = os.path.splitext(filename)[1] if '.' in filename else '.bin'
            file_id = f"{uuid.uuid4().hex}{ext}"
            
            file_path = os.path.join(self.base_path, "files", file_id)
            meta_path = os.path.join(self.base_path, "metadata", f"{file_id}.json")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª –Ω–∞ –¥–∏—Å–∫
            with open(file_path, 'wb') as f:
                f.write(file_content)
            
            # –°–æ–∑–¥–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ
            file_info = {
                'id': file_id,
                'original_name': filename,
                'path': file_path,
                'size': len(file_content),
                'saved_at': datetime.now().isoformat(),
                'metadata': metadata or {}
            }
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤ JSON —Ñ–∞–π–ª
            with open(meta_path, 'w', encoding='utf-8') as f:
                json.dump(file_info, f, ensure_ascii=False, indent=2)
            
            logger.info(f"–§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω –ª–æ–∫–∞–ª—å–Ω–æ: {file_id} ({len(file_content)} –±–∞–π—Ç)")
            return file_info
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")
            raise
    
    async def get(self, file_id: str) -> bytes:
        """–ü–æ–ª—É—á–∞–µ—Ç —Ñ–∞–π–ª –ø–æ ID"""
        try:
            file_path = os.path.join(self.base_path, "files", file_id)
            if not os.path.exists(file_path):
                raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_id}")
            
            with open(file_path, 'rb') as f:
                return f.read()
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: {e}")
            raise
    
    async def delete(self, file_id: str) -> bool:
        """–£–¥–∞–ª—è–µ—Ç —Ñ–∞–π–ª"""
        try:
            file_path = os.path.join(self.base_path, "files", file_id)
            meta_path = os.path.join(self.base_path, "metadata", f"{file_id}.json")
            
            if os.path.exists(file_path):
                os.remove(file_path)
            
            if os.path.exists(meta_path):
                os.remove(meta_path)
            
            logger.info(f"–§–∞–π–ª —É–¥–∞–ª–µ–Ω –ª–æ–∫–∞–ª—å–Ω–æ: {file_id}")
            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: {e}")
            return False
    
    def get_usage_stats(self) -> Dict[str, Any]:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –¥–∏—Å–∫–∞"""
        total_size = 0
        file_count = 0
        
        files_dir = os.path.join(self.base_path, "files")
        if os.path.exists(files_dir):
            for file in os.listdir(files_dir):
                file_path = os.path.join(files_dir, file)
                if os.path.isfile(file_path):
                    total_size += os.path.getsize(file_path)
                    file_count += 1
        
        return {
            'provider': 'local',
            'total_size': total_size,
            'file_count': file_count,
            'path': self.base_path,
            'free_space': shutil.disk_usage(self.base_path).free if os.path.exists(self.base_path) else 0
        }
    
    def cleanup_old_files(self, days: int = 30):
        """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        try:
            cutoff = datetime.now() - timedelta(days=days)
            files_dir = os.path.join(self.base_path, "files")
            meta_dir = os.path.join(self.base_path, "metadata")
            
            if not os.path.exists(files_dir):
                return
            
            for file in os.listdir(files_dir):
                file_path = os.path.join(files_dir, file)
                if os.path.isfile(file_path):
                    file_time = datetime.fromtimestamp(os.path.getmtime(file_path))
                    
                    if file_time < cutoff:
                        os.remove(file_path)
                        
                        meta_file = os.path.join(meta_dir, f"{file}.json")
                        if os.path.exists(meta_file):
                            os.remove(meta_file)
                        
                        logger.info(f"–£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª: {file}")
                        
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤: {e}")

# ==================== –û–ë–õ–ê–ß–ù–û–ï –•–†–ê–ù–ò–õ–ò–©–ï ====================

class CloudStorage(StorageProvider):
    """–û–±–ª–∞—á–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ"""
    
    def __init__(self, provider_type: str = "simulated", config: dict = None):
        self.provider_type = provider_type
        self.config = config or {}
        self.client = None
        logger.info(f"–û–±–ª–∞—á–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ: {provider_type}")
    
    async def save(self, file_content: bytes, filename: str, metadata: dict = None) -> Dict[str, Any]:
        """–°–∏–º—É–ª—è—Ü–∏—è –æ–±–ª–∞—á–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–¥–ª—è —Ç–µ—Å—Ç–æ–≤)"""
        try:
            # –í —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –∑–¥–µ—Å—å –±—É–¥–µ—Ç –∫–æ–¥ –¥–ª—è AWS S3, Yandex Cloud –∏ —Ç.–¥.
            # –î–ª—è —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ—Å—Ç–æ —Å–∏–º—É–ª–∏—Ä—É–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
            await asyncio.sleep(0.1)  # –ò–º–∏—Ç–∞—Ü–∏—è –∑–∞–¥–µ—Ä–∂–∫–∏ —Å–µ—Ç–∏
            
            file_id = f"cloud_{uuid.uuid4().hex}/{filename}"
            
            file_info = {
                'id': file_id,
                'original_name': filename,
                'url': f"https://example.com/{file_id}",
                'size': len(file_content),
                'saved_at': datetime.now().isoformat(),
                'provider': self.provider_type,
                'metadata': metadata or {}
            }
            
            logger.info(f"–§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –æ–±–ª–∞–∫–æ (—Å–∏–º—É–ª—è—Ü–∏—è): {file_id}")
            return file_info
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±–ª–∞—á–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")
            raise
    
    async def get(self, file_id: str) -> bytes:
        """–°–∏–º—É–ª—è—Ü–∏—è –ø–æ–ª—É—á–µ–Ω–∏—è –∏–∑ –æ–±–ª–∞–∫–∞"""
        try:
            await asyncio.sleep(0.1)  # –ò–º–∏—Ç–∞—Ü–∏—è –∑–∞–¥–µ—Ä–∂–∫–∏ 
            # –í —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –∑–¥–µ—Å—å –±—É–¥–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ –æ–±–ª–∞–∫—É
            return b"simulated_cloud_content"
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–∑ –æ–±–ª–∞–∫–∞: {e}")
            raise
    
    async def delete(self, file_id: str) -> bool:
        """–°–∏–º—É–ª—è—Ü–∏—è —É–¥–∞–ª–µ–Ω–∏—è –∏–∑ –æ–±–ª–∞–∫–∞"""
        try:
            await asyncio.sleep(0.1)
            logger.info(f"–§–∞–π–ª —É–¥–∞–ª–µ–Ω –∏–∑ –æ–±–ª–∞–∫–∞ (—Å–∏–º—É–ª—è—Ü–∏—è): {file_id}")
            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –∏–∑ –æ–±–ª–∞–∫–∞: {e}")
            return False
    
    def get_usage_stats(self) -> Dict[str, Any]:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±–ª–∞—á–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞"""
        return {
            'provider': self.provider_type,
            'total_size': 0,
            'file_count': 0,
            'status': 'simulated'
        }

# ==================== –ì–ò–ë–†–ò–î–ù–û–ï –•–†–ê–ù–ò–õ–ò–©–ï ====================

class HybridStorage:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞"""
    
    MODES = {
        'local': '–¢–æ–ª—å–∫–æ –ª–æ–∫–∞–ª—å–Ω–æ',
        'cloud': '–¢–æ–ª—å–∫–æ –æ–±–ª–∞–∫–æ', 
        'both': '–õ–æ–∫–∞–ª—å–Ω–æ + –û–±–ª–∞–∫–æ',
        'mirror': '–ó–µ—Ä–∫–∞–ª–∏—Ä–æ–≤–∞–Ω–∏–µ (—É–¥–∞–ª–µ–Ω–∏–µ –≤ –æ–±–æ–∏—Ö)'
    }

    
    def __init__(self, local_config: dict = None, cloud_config: dict = None):

        self.max_file_size_bytes = 50 * 1024 * 1024  # 50MB –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        self.auto_cleanup_days = 30
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
        local_base = local_config.get('base_path', './storage') if local_config else './storage'
        self.local = LocalStorage(local_base)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ –ª–∏ –æ–±–ª–∞–∫–æ
        self.cloud = None
        if cloud_config and cloud_config.get('enabled', False):
            provider = cloud_config.get('provider', 'simulated')
            self.cloud = CloudStorage(provider, cloud_config)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        self.mode = 'local'
        self.db_path = os.path.join(local_base, 'storage_meta.db')
        self._init_database()
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞
        self.auto_cleanup_days = 30
        self.local.cleanup_old_files(self.auto_cleanup_days)

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
        local_base = local_config.get('base_path', './storage') if local_config else './storage'
        self.local = LocalStorage(local_base)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–±–ª–∞—á–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
        self.cloud = None
        if cloud_config and cloud_config.get('enabled', False):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–µ—Ä–µ–¥–∞–ª–∏ –ª–∏ —Ä–µ–∞–ª—å–Ω—ã–π –æ–±—ä–µ–∫—Ç –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
            if isinstance(cloud_config.get('provider'), YandexCloudStorage):
                self.cloud = cloud_config['provider']
                logger.info(f"‚òÅÔ∏è –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ Yandex Cloud —Ö—Ä–∞–Ω–∏–ª–∏—â–µ")
            else:
                # –ò–Ω–∞—á–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–≥–ª—É—à–∫—É
                self.cloud = CloudStorage('simulated', {})
                
            logger.info(f"‚òÅÔ∏è –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —Å–∏–º—É–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–±–ª–∞—á–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ")

        
        logger.info(f"–ì–∏–±—Ä–∏–¥–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ. –†–µ–∂–∏–º: {self.mode}")
    
    def _init_database(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute('''
                CREATE TABLE IF NOT EXISTS files (
                    id TEXT PRIMARY KEY,
                    original_name TEXT NOT NULL,
                    local_path TEXT,
                    cloud_id TEXT,
                    cloud_provider TEXT,
                    file_size INTEGER,
                    created_at TEXT NOT NULL,
                    storage_mode TEXT NOT NULL,
                    metadata TEXT
                )
            ''')
            
            conn.execute('''
                CREATE TABLE IF NOT EXISTS storage_settings (
                    key TEXT PRIMARY KEY,
                    value TEXT NOT NULL
                )
            ''')
            
            conn.execute('''
                CREATE INDEX IF NOT EXISTS idx_created_at ON files(created_at)
            ''')
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º
            conn.execute('''
                INSERT OR REPLACE INTO storage_settings (key, value)
                VALUES ('mode', ?)
            ''', (self.mode,))
            
            conn.commit()
    
    async def save_file(self, file_content: bytes, filename: str, metadata: dict = None) -> Dict[str, Any]:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ñ–∞–π–ª —Å–æ–≥–ª–∞—Å–Ω–æ —Ç–µ–∫—É—â–µ–º—É —Ä–µ–∂–∏–º—É"""
        file_size = len(file_content)
        if file_size > self.max_file_size_bytes:
            raise ValueError(
                f"–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π! "
                f"–†–∞–∑–º–µ—Ä: {file_size / 1024 / 1024:.1f} –ú–ë, "
                f"–º–∞–∫—Å–∏–º—É–º: {self.max_file_size_bytes / 1024 / 1024} –ú–ë"
            )
    
        file_id = str(uuid.uuid4())
        results = {'id': file_id, 'mode': self.mode}
        
        try:
            # –†–ï–ñ–ò–ú: –¢–æ–ª—å–∫–æ –ª–æ–∫–∞–ª—å–Ω–æ
            if self.mode == 'local':
                local_info = await self.local.save(file_content, filename, metadata)
                results['local'] = local_info
                self._save_to_db(file_id, filename, local_info.get('path'), None, len(file_content), metadata)
            
            # –†–ï–ñ–ò–ú: –¢–æ–ª—å–∫–æ –æ–±–ª–∞–∫–æ
            elif self.mode == 'cloud':
                if not self.cloud:
                    raise Exception("–û–±–ª–∞—á–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ")
                
                cloud_info = await self.cloud.save(file_content, filename, metadata)
                results['cloud'] = cloud_info
                self._save_to_db(file_id, filename, None, cloud_info.get('id'), len(file_content), metadata)
            
            # –†–ï–ñ–ò–ú: –õ–æ–∫–∞–ª—å–Ω–æ + –û–±–ª–∞–∫–æ
            elif self.mode == 'both':
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª–æ–∫–∞–ª—å–Ω–æ
                local_info = await self.local.save(file_content, filename, metadata)
                results['local'] = local_info
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –æ–±–ª–∞–∫–æ (–µ—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ)
                cloud_id = None
                if self.cloud:
                    try:
                        cloud_info = await self.cloud.save(file_content, filename, metadata)
                        results['cloud'] = cloud_info
                        cloud_id = cloud_info.get('id')
                    except Exception as e:
                        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –æ–±–ª–∞–∫–æ: {e}")
                
                self._save_to_db(file_id, filename, local_info.get('path'), cloud_id, len(file_content), metadata)
            
            # –†–ï–ñ–ò–ú: –ó–µ—Ä–∫–∞–ª–∏—Ä–æ–≤–∞–Ω–∏–µ
            elif self.mode == 'mirror':
                if not self.cloud:
                    raise Exception("–î–ª—è —Ä–µ–∂–∏–º–∞ mirror –Ω—É–∂–Ω–æ –æ–±–ª–∞—á–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –æ–±–æ–∏—Ö –º–µ—Å—Ç–∞—Ö
                local_info = await self.local.save(file_content, filename, metadata)
                cloud_info = await self.cloud.save(file_content, filename, metadata)
                
                results['local'] = local_info
                results['cloud'] = cloud_info
                
                self._save_to_db(file_id, filename, local_info.get('path'), cloud_info.get('id'), len(file_content), metadata)
            
            logger.info(f"–§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ä–µ–∂–∏–º–µ {self.mode}: {filename}")
            return results
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
            # –û—Ç–∫–∞—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ
            await self._rollback_save(results)
            raise
    
    def _save_to_db(self, file_id: str, filename: str, local_path: str, cloud_id: str, size: int, metadata: dict = None):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ –≤ –ë–î"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute('''
                INSERT INTO files (id, original_name, local_path, cloud_id, cloud_provider, file_size, created_at, storage_mode, metadata)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                file_id, filename, local_path, cloud_id,
                self.cloud.provider_type if self.cloud else None,
                size, datetime.now().isoformat(), self.mode,
                json.dumps(metadata or {}) if metadata else None
            ))
            conn.commit()
    
    async def _rollback_save(self, results: Dict[str, Any]):
        """–û—Ç–∫–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–∏ –æ—à–∏–±–∫–µ"""
        try:
            if 'local' in results and 'id' in results['local']:
                await self.local.delete(results['local']['id'])
            
            if 'cloud' in results and 'id' in results['cloud'] and self.cloud:
                await self.cloud.delete(results['cloud']['id'])
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–∫–∞—Ç–µ: {e}")
    
    async def get_file(self, file_id: str) -> Tuple[bytes, Dict[str, Any]]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Ñ–∞–π–ª –ø–æ ID"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ë–î
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute('''
                    SELECT local_path, cloud_id, storage_mode FROM files WHERE id = ?
                ''', (file_id,))
                row = cursor.fetchone()
                
                if not row:
                    raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ë–î: {file_id}")
                
                local_path, cloud_id, mode = row
                
                # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
                if mode in ['local', 'both', 'mirror'] and local_path:
                    if os.path.exists(local_path):
                        with open(local_path, 'rb') as f:
                            return f.read(), {'source': 'local', 'path': local_path}
                
                # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –æ–±–ª–∞–∫–∞
                if mode in ['cloud', 'both', 'mirror'] and cloud_id and self.cloud:
                    try:
                        content = await self.cloud.get(cloud_id)
                        return content, {'source': 'cloud', 'cloud_id': cloud_id}
                    except Exception as e:
                        logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –æ–±–ª–∞–∫–∞: {e}")
                
                raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {file_id}")
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {file_id}: {e}")
            raise
    
    async def delete_file(self, file_id: str) -> bool:
        """–£–¥–∞–ª—è–µ—Ç —Ñ–∞–π–ª"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute('''
                    SELECT local_path, cloud_id, storage_mode FROM files WHERE id = ?
                ''', (file_id,))
                row = cursor.fetchone()
                
                if not row:
                    return False
                
                local_path, cloud_id, mode = row
                success = True
                
                # –£–¥–∞–ª—è–µ–º –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
                if mode in ['local', 'both', 'mirror'] and local_path:
                    if os.path.exists(local_path):
                        try:
                            # –ù–∞—Ö–æ–¥–∏–º ID —Ñ–∞–π–ª–∞ –≤ –ª–æ–∫–∞–ª—å–Ω–æ–º —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
                            file_name = os.path.basename(local_path)
                            await self.local.delete(file_name)
                        except Exception as e:
                            logger.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞: {e}")
                            success = False
                
                # –£–¥–∞–ª—è–µ–º –∏–∑ –æ–±–ª–∞–∫–∞
                if mode in ['cloud', 'both', 'mirror'] and cloud_id and self.cloud:
                    try:
                        await self.cloud.delete(cloud_id)
                    except Exception as e:
                        logger.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –∏–∑ –æ–±–ª–∞–∫–∞: {e}")
                        success = False
                
                # –£–¥–∞–ª—è–µ–º –∑–∞–ø–∏—Å—å –∏–∑ –ë–î
                conn.execute('DELETE FROM files WHERE id = ?', (file_id,))
                conn.commit()
                
                logger.info(f"–§–∞–π–ª —É–¥–∞–ª–µ–Ω: {file_id}")
                return success
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {file_id}: {e}")
            return False
    
    def switch_mode(self, new_mode: str) -> bool:
        """–ü–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç —Ä–µ–∂–∏–º —Ö—Ä–∞–Ω–µ–Ω–∏—è"""
        if new_mode not in self.MODES:
            logger.error(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ä–µ–∂–∏–º: {new_mode}")
            return False
        
        old_mode = self.mode
        self.mode = new_mode
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
        with sqlite3.connect(self.db_path) as conn:
            conn.execute('''
                INSERT OR REPLACE INTO storage_settings (key, value)
                VALUES ('mode', ?)
            ''', (new_mode,))
            conn.commit()
        
        logger.info(f"–†–µ–∂–∏–º —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω: {old_mode} -> {new_mode}")
        return True
    
    def get_current_mode(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º"""
        return {
            'mode': self.mode,
            'description': self.MODES.get(self.mode, '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'),
            'providers': {
                'local': True,
                'cloud': self.cloud is not None
            }
        }
    
    def get_stats(self) -> Dict[str, Any]:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞"""
        local_stats = self.local.get_usage_stats()
        cloud_stats = self.cloud.get_usage_stats() if self.cloud else {'provider': 'not_configured'}
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –∏–∑ –ë–î
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute('SELECT COUNT(*) FROM files')
            total_files = cursor.fetchone()[0]
            
            cursor = conn.execute('''
                SELECT storage_mode, COUNT(*) 
                FROM files 
                GROUP BY storage_mode
            ''')
            files_by_mode = dict(cursor.fetchall())
        
        return {
            'total_files': total_files,
            'files_by_mode': files_by_mode,
            'local': local_stats,
            'cloud': cloud_stats,
            'current_mode': self.mode
        }

# ==================== –°–ò–°–¢–ï–ú–ê –ë–≠–ö–ê–ü–û–í ====================

class BackupSystem:
    """–°–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –±—ç–∫–∞–ø–æ–≤"""
    
    def __init__(self, storage: HybridStorage, backup_dir: str = "./backups"):
        self.storage = storage
        self.backup_dir = os.path.abspath(backup_dir)
        self._ensure_backup_dir()
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –±—ç–∫–∞–ø–æ–≤
        self.backup_interval_days = 3
        self.keep_backups = 5
        
        logger.info(f"–°–∏—Å—Ç–µ–º–∞ –±—ç–∫–∞–ø–æ–≤: {self.backup_dir}, –∏–Ω—Ç–µ—Ä–≤–∞–ª: {self.backup_interval_days} –¥–Ω–µ–π")
    
    def _ensure_backup_dir(self):
        """–°–æ–∑–¥–∞–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –±—ç–∫–∞–ø–æ–≤"""
        os.makedirs(self.backup_dir, exist_ok=True)
        os.makedirs(os.path.join(self.backup_dir, "full"), exist_ok=True)
        os.makedirs(os.path.join(self.backup_dir, "logs"), exist_ok=True)
    
    async def create_backup(self, backup_type: str = "full") -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–µ—Ç –±—ç–∫–∞–ø"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_name = f"{backup_type}_backup_{timestamp}"
            
            backup_path = os.path.join(self.backup_dir, "full", f"{backup_name}.zip")
            
            with zipfile.ZipFile(backup_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                # –ë—ç–∫–∞–ø –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
                if os.path.exists(self.storage.db_path):
                    zipf.write(self.storage.db_path, "storage_meta.db")
                
                # –ë—ç–∫–∞–ø –ª–æ–∫–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
                local_files_dir = os.path.join(self.storage.local.base_path, "files")
                if os.path.exists(local_files_dir):
                    for root, dirs, files in os.walk(local_files_dir):
                        for file in files:
                            file_path = os.path.join(root, file)
                            arcname = os.path.relpath(file_path, self.storage.local.base_path)
                            zipf.write(file_path, arcname)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –±—ç–∫–∞–ø–µ
                settings = {
                    'backup_type': backup_type,
                    'created_at': datetime.now().isoformat(),
                    'storage_mode': self.storage.mode,
                    'file_count': self._count_files(local_files_dir) if os.path.exists(local_files_dir) else 0
                }
                
                zipf.writestr("backup_info.json", json.dumps(settings, indent=2))
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –ª–æ–≥
            self._log_backup(backup_name, backup_path, backup_type)
            
            # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –±—ç–∫–∞–ø—ã
            self._cleanup_old_backups()
            
            logger.info(f"–ë—ç–∫–∞–ø —Å–æ–∑–¥–∞–Ω: {backup_name}")
            return {
                'name': backup_name,
                'path': backup_path,
                'type': backup_type,
                'size': os.path.getsize(backup_path) if os.path.exists(backup_path) else 0,
                'created_at': timestamp
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –±—ç–∫–∞–ø–∞: {e}")
            raise
    
    def _count_files(self, directory: str) -> int:
        """–°—á–∏—Ç–∞–µ—Ç —Ñ–∞–π–ª—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
        count = 0
        if os.path.exists(directory):
            for root, dirs, files in os.walk(directory):
                count += len(files)
        return count
    
    def _log_backup(self, backup_name: str, backup_path: str, backup_type: str):
        """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –ª–æ–≥ –±—ç–∫–∞–ø–∞"""
        log_file = os.path.join(self.backup_dir, "logs", "backup_history.log")
        
        log_entry = {
            'name': backup_name,
            'path': backup_path,
            'type': backup_type,
            'created_at': datetime.now().isoformat(),
            'size': os.path.getsize(backup_path) if os.path.exists(backup_path) else 0
        }
        
        with open(log_file, 'a', encoding='utf-8') as f:
            f.write(json.dumps(log_entry, ensure_ascii=False) + '\n')
    
    def _cleanup_old_backups(self):
        """–£–¥–∞–ª—è–µ—Ç —Å—Ç–∞—Ä—ã–µ –±—ç–∫–∞–ø—ã"""
        try:
            backup_dir = os.path.join(self.backup_dir, "full")
            if not os.path.exists(backup_dir):
                return
            
            backups = []
            for file in os.listdir(backup_dir):
                if file.endswith('.zip'):
                    file_path = os.path.join(backup_dir, file)
                    backups.append((file_path, os.path.getmtime(file_path)))
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–Ω–æ–≤—ã–µ —Å–Ω–∞—á–∞–ª–∞)
            backups.sort(key=lambda x: x[1], reverse=True)
            
            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ, –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ keep_backups
            for backup_path, _ in backups[self.keep_backups:]:
                os.remove(backup_path)
                logger.info(f"–£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π –±—ç–∫–∞–ø: {os.path.basename(backup_path)}")
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –±—ç–∫–∞–ø–æ–≤: {e}")
    
    async def start_auto_backups(self, days_interval: int = 3):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –±—ç–∫–∞–ø—ã –∫–∞–∂–¥—ã–µ N –¥–Ω–µ–π"""
        logger.info(f"üöÄ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –±—ç–∫–∞–ø—ã –∑–∞–ø—É—â–µ–Ω—ã (–∫–∞–∂–¥—ã–µ {days_interval} –¥–Ω–µ–π)")
        
        while True:
            try:
                await asyncio.sleep(60 * 60)  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π —á–∞—Å
                
                # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –±—ç–∫–∞–ø
                backup_dir = os.path.join(self.backup_dir, "full")
                if not os.path.exists(backup_dir):
                    # –ï—Å–ª–∏ –ø–∞–ø–∫–∏ –Ω–µ—Ç, —Å–æ–∑–¥–∞–µ–º –ø–µ—Ä–≤—ã–π –±—ç–∫–∞–ø
                    await self.create_backup("full")
                    continue
                
                backups = []
                for file in os.listdir(backup_dir):
                    if file.endswith('.zip'):
                        file_path = os.path.join(backup_dir, file)
                        backups.append((file_path, os.path.getmtime(file_path)))
                
                if not backups:
                    # –ù–µ—Ç –±—ç–∫–∞–ø–æ–≤ - —Å–æ–∑–¥–∞–µ–º –ø–µ—Ä–≤—ã–π
                    await self.create_backup("full")
                else:
                    # –ù–∞—Ö–æ–¥–∏–º —Å–∞–º—ã–π –Ω–æ–≤—ã–π –±—ç–∫–∞–ø
                    latest_backup = max(backups, key=lambda x: x[1])
                    last_time = datetime.fromtimestamp(latest_backup[1])
                    days_since = (datetime.now() - last_time).days
                    
                    if days_since >= days_interval:
                        logger.info(f"‚è∞ –ü—Ä–æ—à–ª–æ {days_since} –¥–Ω–µ–π, —Å–æ–∑–¥–∞—é –Ω–æ–≤—ã–π –±—ç–∫–∞–ø")
                        await self.create_backup("full")
                    else:
                        days_left = days_interval - days_since
                        logger.debug(f"‚è≥ –î–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –±—ç–∫–∞–ø–∞: {days_left} –¥–Ω–µ–π")
                        
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –≤ –∞–≤—Ç–æ-–±—ç–∫–∞–ø–µ: {e}")
                await asyncio.sleep(300)  # –ñ–¥–µ–º 5 –º–∏–Ω—É—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ